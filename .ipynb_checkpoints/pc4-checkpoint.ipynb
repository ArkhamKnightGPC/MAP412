{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC 4 : Méthodes directes pour la résolution de systèmes linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<big> Préparation avant la PC :</big>** \n",
    "**Les questions 1 et 2 de l'exercice 1 sont à préparer** avant la séance de PC du 21/09. \n",
    "\n",
    "**<big><font color=black><span style=\"background-color:skyblue\">À rendre</span></font> après la PC :</big>**\n",
    "**Les exercices 1, 2 et 3 contiennent des parties <font color=black><span style=\"background-color:skyblue\">à rendre</span></font> avant le 25/09 à 20h00. La question 5.4) l'exercice 1 et les questions 2.6), 2.7) et 3) de l'exercice 3 sont en <font color=black><span style=\"background-color:deepskyblue\">bonus</span></font>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce package permet de travailler efficacement avec des tableaux\n",
    "import numpy as np\n",
    "# Ce package propose de fonctions d'aglebre lineaire (inverse, determinant...)\n",
    "import numpy.linalg as lin\n",
    "# Ces fonctions sont utilisees comme reference pour la decomposition LU\n",
    "from scipy.linalg import lu_factor, lu_solve, solve_banded\n",
    "\n",
    "# Ce package permet de faire des sorties graphiques\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Cette fonction permet de comparer des temps d'execution\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Rappels et notations :**\n",
    ">\n",
    ">- Étant donnée une norme $\\left\\Vert \\cdot \\right\\Vert$ sur $\\mathbb K^n$ ($\\mathbb{K}=\\mathbb{R}$ ou $\\mathbb{C}$), on définit la norme subordonnée associée sur $M_n(\\mathbb{K})$ par\n",
    ">\n",
    ">$$\\left\\Vert A \\right\\Vert = \\sup_{\\substack{x\\in\\mathbb{K}^n \\\\ x\\neq 0}} \\frac{\\left\\Vert Ax \\right\\Vert}{\\left\\Vert x \\right\\Vert} = \\max_{\\substack{x\\in\\mathbb{K}^n \\\\ \\left\\Vert x \\right\\Vert= 1}}\\left\\Vert Ax \\right\\Vert.$$\n",
    ">\n",
    ">- Une norme $\\left\\Vert \\cdot \\right\\Vert$ sur $M_n(\\mathbb K)$ ($\\mathbb K = \\mathbb R$ ou $\\mathbb C$) est dite matricielle (ou d'algèbre) si \n",
    ">\n",
    ">$$\\forall A,B \\in M_n(\\mathbb K),\\quad{} \\left\\Vert AB\\right\\Vert \\leq \\left\\Vert A\\right\\Vert \\left\\Vert B\\right\\Vert.$$\n",
    ">\n",
    ">- Les normes subordonnées sont des normes matricielles. Il existe des normes matricielles qui ne sont pas des normes subordonnées, par exemple la norme de Frobenius : $\\left\\Vert A\\right\\Vert_F = \\sqrt{\\mathrm{tr}(A^{*}A)}$.\n",
    ">\n",
    ">- Pour tout matrice $A\\in M_n(\\mathbb{K})$ inversible, on définit son conditionnement, associé à une norme subordonnée $\\left\\Vert \\cdot \\right\\Vert$, par\n",
    ">\n",
    ">$$\\kappa(A) = \\Vert A \\Vert \\Vert A^{-1} \\Vert.$$\n",
    ">\n",
    ">- Soit $A\\in M_n(\\mathbb{K})$, on appelle rayon spectral de $A$ la quantité\n",
    ">\n",
    ">$$\\rho(A)=\\max\\limits_{\\lambda\\in \\mathrm{Sp}(A)} \\vert\\lambda\\vert.$$\n",
    ">\n",
    ">- Si $A$ est une matrice normale (c'est à dire telle que $A^*A=AA^*$), $\\left\\Vert A \\right\\Vert_2 = \\rho(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Conditionnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : Conditionnement local par rapport au scond membre\n",
    "\n",
    ">Soit $A$ est une matrice réelle inversible de taille $n \\times n$. Pour un vecteur $b \\in \\mathbb{R}^n$ on cherche à résoudre le système\n",
    ">\n",
    ">$$ Ax=b, $$\n",
    ">\n",
    ">et on note $\\mathcal{P}(b)=A^{-1}b$ avec $A$ fixée. On étudie la variabilité de la solution $x$ par rapport aux erreurs sur le terme $b$ à droite du système. Pour cela, on définit le *conditionnement local* associé au problème $\\mathcal{P}$ pour tout $b \\in \\mathbb{R}^n\\setminus\\{0\\}$ par\n",
    ">\n",
    ">$$\\kappa_b(A) = \\frac{1}{\\varepsilon} \\sup_{\\frac{\\left\\Vert \\delta b \\right\\Vert}{\\left\\Vert b \\right\\Vert}\\leq \\varepsilon} \\frac{\\left\\Vert \\mathcal{P}(b+\\delta b) - \\mathcal{P}(b) \\right\\Vert}{\\left\\Vert \\mathcal{P}(b) \\right\\Vert}.$$\n",
    "\n",
    "$1$. Comparer $\\kappa_b(A)$ et $\\kappa(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    $$\\begin{align}\n",
    "        \\kappa_b(A) &= \\frac{1}{\\epsilon} \\sup_{\\frac{||\\delta b||}{||b||} \\leq \\epsilon} \\left( \\frac{||A^{-1} \\delta b||}{||A^{-1} b||} \\right) \\\\\n",
    "        &\\leq \\frac{1}{\\epsilon} \\sup_{\\frac{||\\delta b||}{||b||} \\leq \\epsilon} \\left( \\frac{||A^{-1}|| \\cdot ||\\delta b||}{||A^{-1} b||} \\right) \\\\\n",
    "        &= \\frac{||A^{-1}|| \\cdot ||b||}{||A^{-1} b||}\\\\\n",
    "        &\\leq \\frac{||A^{-1}|| \\cdot ||A|| \\cdot ||A^{-1}{b}||}{||A^{-1} b||}\\\\\n",
    "        &= ||A|| \\cdot ||A^{-1}|| = \\kappa(A).\n",
    "    \\end{align}$$\n",
    "    On en conclue $\\kappa_b(A) \\leq \\kappa(A)$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$.  Montrer qu'il existe $b_1 \\in \\mathbb{R}^n\\setminus\\{0\\}$ tel que $\\kappa_{b_1}(A) = \\kappa(A)$, et $b_2 \\in \\mathbb{R}^n\\setminus\\{0\\}$ tel que $\\kappa_{b_2}(A) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Soit $x \\in \\mathbb{R}^n \\setminus  \\{0\\}$ tel que $||Ax|| = ||A|| \\cdot ||x||$.\n",
    "    On note que cet $x$ existe, une fois que $||A|| = \\sup_{||x|| = 1} ||Ax||$. $\\\\$\n",
    "    Alors, on pose $b_1 \\in \\mathbb{R}^n \\setminus \\{0\\}$ tel que $A^{-1} b_1 = x \\implies b_1 = Ax$.\n",
    "    On pose $\\delta b_1$ tel que $||A^{-1} \\delta b_1|| = ||A^{-1}|| ||\\delta b_1||$ et $\\frac{||\\delta b_1||}{||b_1||} = \\epsilon$.\n",
    "    Donc, on a $\\kappa_{b_1}(A) = \\kappa(A)$. $\\\\$\n",
    "    On pose $b_2$ tel que $||A^{-1} b_2|| = ||A^{-1}|| \\cdot ||b_2|| \\implies \\kappa_{b_2}(A) = 1$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. Montrer que, pour tout $b \\in \\mathbb{R}^n\\setminus\\{0\\}$ et tout $\\delta b \\in \\mathbb{R}^n\\setminus\\{0\\}$, si\n",
    "\n",
    "$$ Ax=b \\qquad{}\\text{et}\\qquad{} A(x+\\delta x)=b+\\delta b, $$\n",
    "\n",
    "alors\n",
    "\n",
    "$$ \\frac{\\left\\Vert \\delta x \\right\\Vert}{\\left\\Vert x \\right\\Vert} \\leq \\kappa_b(A) \\frac{\\left\\Vert \\delta b \\right\\Vert}{\\left\\Vert b \\right\\Vert} \\leq \\kappa(A) \\frac{\\left\\Vert \\delta b \\right\\Vert}{\\left\\Vert b \\right\\Vert}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    On a le système\n",
    "    $$\\begin{align}\n",
    "    \\begin{cases}\n",
    "    Ax &= b \\\\\n",
    "    A\\delta x &= \\delta b\n",
    "    \\end{cases}\n",
    "    \\end{align}$$\n",
    "    Alors, on a\n",
    "    $$ \\frac{||\\delta x||}{||x||} = \\frac{||A^{-1} \\delta b||}{||A^{-1} b||} \\leq \\epsilon \\kappa_b(A) = \\kappa_b(A) \\frac{||\\delta b||}{||b||} \\leq \\kappa(A)\\frac{||\\delta b||}{||b||}.$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Conditionnement par rapport à la matrice et au second membre\n",
    "\n",
    ">On étudie dans un premier temps la variabilité de la solution $x$ par rapport aux erreurs sur la matrice $A$ seule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$. Montrer que pour tout $\\delta A$ telle que $\\|\\delta A\\| < \\frac{1}{\\|A^{-1}\\|}$ alors $A+\\delta A$ est inversible. Et montrer que \n",
    "\n",
    "$$\\|(A+\\delta A)^{-1}\\| \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\delta A\\|}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    On a $A + \\delta A = A(I + A^{-1}\\delta A)$. Alors,\n",
    "    $$\\begin{align}\n",
    "        (A + \\delta A)^{-1} &= (I + A^{-1}\\delta A)^{-1} A^{-1}\\\\\n",
    "        &= \\left(\\sum_{k=0}^{+\\infty} (-1)^k (A \\delta A)^k \\right) A^{-1}\n",
    "    \\end{align}$$\n",
    "    Donc \n",
    "    $$\\begin{align}\n",
    "        \\|(A + \\delta A)^{-1}\\| &\\leq \\left(\\sum_{k=0}^{+\\infty} \\|A \\delta A\\|^k \\right) \\|A^{-1}\\|\\\\\n",
    "        &= \\frac{\\|A^{-1}\\|}{1 - \\|A^{-1} \\delta A\\|}\\\\\n",
    "        &\\leq \\frac{\\|A^{-1}\\|}{1 - \\|A^{-1}\\| \\|\\delta A \\|}\n",
    "    \\end{align}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. Montrer que pour tout $\\delta A$ et $\\delta x$ satisfaisant\n",
    "\n",
    "$$ (A+\\delta A) (x+\\delta x) = b,$$\n",
    "\n",
    "alors on a l'estimation \n",
    "\n",
    "$$ \\frac{\\|\\delta x\\|}{\\|x + \\delta x\\|} \\le \\kappa \\frac{\\|\\delta A\\|}{\\|A\\|}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On étudie finalement la variabilité de la solution $x$ par rapport aux erreurs sur la matrice $A$ et sur le second membre $b$ ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. On écrit désormais \n",
    "\n",
    "$$ (A+\\delta A) (x+\\delta x) = b+\\delta b.$$ \n",
    "\n",
    "Montrer que pour tout $\\delta A$ telle que $\\|\\delta A\\| < \\frac{1}{\\|A^{-1}\\|}$, on a \n",
    "\n",
    "$$\\frac{\\|\\delta x\\|}{\\| x \\|} \\le \\frac{\\kappa}{1-\\|A^{-1}\\|\\|\\delta A\\|} \\left(\\frac{\\|\\delta A\\|}{\\|A\\|} + \\frac{\\|\\delta b\\|}{\\|b\\|}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$. On revient sur les systèmes $Ax = b$ de la PC1 avec\n",
    "\n",
    "- a) $A = \\left( \\begin{array}{cc} 1+\\alpha & -1 \\\\ 1 & -1 \\end{array}\\right)$ et $b = \\left(\\begin{array}{c} \\alpha \\\\ 0 \\end{array}\\right)$, \n",
    "- b) $A = \\left( \\begin{array}{cc}   \\alpha &  1 \\\\ 1 &  1 \\end{array}\\right)$ et $b = \\left(\\begin{array}{c} 1 \\\\ 2 \\end{array}\\right)$.\n",
    "\n",
    "Donner une estimation de $\\frac{\\|\\delta x\\|_\\infty}{\\|x\\|_\\infty}$ dans chaque cas en fonction de $\\alpha$ et évaluer pour $\\alpha = 2^{-52}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Montrez que si $A$ est une matrice symétrique réelle alors\n",
    "  \n",
    "$$ \\kappa_2(A) = \\frac{\\max\\limits_{\\lambda\\in Sp(A)} \\vert\\lambda\\vert}{\\min\\limits_{\\lambda\\in Sp(A)} \\vert\\lambda\\vert}, $$\n",
    "\n",
    "où $\\kappa_2$ désigne le conditionnement pour la norme $\\left\\Vert \\cdot \\right\\Vert_2$.\n",
    "\n",
    "*Indication :* On pourra utiliser le fait que $A$ est diagonalisable dans une base orthonormée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Considérons l'exemple suivant (attribué à H. Rutishauser [1]) : \n",
    "    \n",
    "$$\n",
    "    A=\\begin{pmatrix}\n",
    "      10 & 1 & 4 & 0 \\\\\n",
    "      1  & 10& 5 & -1\\\\\n",
    "      4 & 5 & 10 & 7 \\\\\n",
    "      0 & -1 & 7 & 9\n",
    "    \\end{pmatrix}\n",
    "    \\text{ avec } \n",
    "    b_1 = \\begin{pmatrix}\n",
    "    15\\\\15\\\\26\\\\15\n",
    "    \\end{pmatrix}\n",
    "    \\text{ et }\n",
    "    b_2 = \\begin{pmatrix}\n",
    "    16\\\\16\\\\25\\\\16\n",
    "    \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition de la matrice\n",
    "A = np.array([[10.,  1.,  4.,  0.],\n",
    "              [ 1., 10.,  5., -1.],\n",
    "              [ 4.,  5., 10.,  7.],\n",
    "              [ 0., -1.,  7.,  9.]])\n",
    "\n",
    "# defition des vecteurs\n",
    "b1 = np.array([15.,  15.,  26.,  15.])\n",
    "b2 = np.array([16.,  16.,  25.,  16.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$. **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Calculer le déterminant de $A$ et l'inverse de $A$ avec les fonctions *numpy.linalg.det* et *numpy.linalg.inv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Déterminant via det :\", )\n",
    "print(\"Inverse     via inv :\\n\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Résoudre les systèmes $Ax_1=b_1$ et $Ax_2 = b_2$ en utilisant soit l'inverse trouvée ci-dessus, soit *numpy.linalg.solve*. Calculer l'erreur relative $\\frac{\\|x_1-x_2\\|}{\\|x_1\\|}$ et commenter cette valeur. En déduire une borne inférieure sur le conditionnement (en norme 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erreur relative sur x : \", )\n",
    "print(\"borne inf du conditionnement : \", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Calculer le conditionnement (en norme 2) de $A$ **par les deux** méthodes suivantes :\n",
    "- calculer les valeurs propres de $A$ avec *numpy.linalg.eig* et en utilisant la question 2,\n",
    "- utiliser *numpy.linalg.cond*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conditionnement via eig  : \", )\n",
    "print(\"Conditionnement via cond : \", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$. **<font color=black><span style=\"background-color:deepskyblue\"> Bonus :</span></font>** Trouver un vecteur $b$ tel que, pour toute perturbation $\\delta b$, on ait \n",
    "\n",
    "$$\\frac{\\left\\Vert \\delta x \\right\\Vert_2}{\\left\\Vert x \\right\\Vert_2} \\leq  \\frac{\\left\\Vert \\delta b \\right\\Vert_2}{\\left\\Vert b \\right\\Vert_2}.$$\n",
    "\n",
    "*Justifiez votre réponse de manière théorique. On vérifiera ensuite numériquement que l'inégalité est vérifiée au moins pour 4 vecteurs de perturbation $\\delta b$ linéairement indépendant.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"vecteur considéré :\", )\n",
    "print(\"Erreur relative sur x :\", )\n",
    "print(\"Erreur relative sur b :\", ,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 :\n",
    "\n",
    "1) On rappelle que le polynôme d'interpolation aux points de Tchebychev dans la base polynomiale de Tchebychev s'écrit \n",
    "\n",
    "$$ p_n(f) = \\sum\\limits_{i=0}^n c_i T_i, \\qquad{} \\text{avec}\\qquad{} c_0 = \\frac{1}{n+1}\\sum_{i=0}^n T_0(x_i) y_i, \\qquad{} c_j = \\frac{2}{n+1}\\sum_{i=0}^n T_j(x_i) y_i \\quad{}\\forall j= 1, \\dots, n. $$\n",
    "\n",
    "En écrivant $M$ la matrice telle que $M c = y$ où $c$ est le vecteur de coefficient dans la base de Tchebychev et $y$ est le vecteur des ordonnées telles que $p_n(f)(x_i) = y_i$, montrer que le conditionnement en norme 2 de $M$ vaut  $\\sqrt{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) a) Calculer numériquement le conditionnement en norme 2 de cette matrice $M$ pour un nombre de points $n = 2^1, 2^2, \\dots, 2^8$. \n",
    "\n",
    "*Indication :* On pourra utiliser la fonction numpy.linalg.cond de numpy.\n",
    "\n",
    "b) On cherche maintenant les coefficients du polynôme d'interpolation aux points équidistants dans la base des polynômes de Tchebychev. On écrit donc \n",
    "\n",
    "$$ p_n(f) = \\sum\\limits_{i=0}^n c_i T_i, $$\n",
    "\n",
    "tel que $p_n(f)(x_i) = y_i = \\sum\\limits_{j=1}^n L_{i,j} c_j$.\n",
    "\n",
    "- Calculer numériquement le conditionnement de la matrice $L$ pour un nombre de points $n = 2^1, 2^2, \\dots, 2^8$. \n",
    "- Tracer ce conditionnement $cond(L)$ en fonction du nombre de points $n$ en échelle log-log.\n",
    "- Comparer les conditionnements de ces deux méthodes et interpréter en lien avec le chapitre 2.\n",
    "\n",
    "*Indication :* On pourra utiliser les fonctions cos et arccos de numpy pour calculer les $L_{i,j}$ et la fonction cond pour le conditionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "N      = 8\n",
    "\n",
    "\n",
    "print(\"Conditionnement des matrices M :\\n\", cond_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "N      = 8\n",
    "\n",
    "print(\"Conditionnement des matrices L :\\n\", cond_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(list_n, cond_L, label=\"cond\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Décomposition $QR$ et résolution de systèmes surdimensionnés\n",
    ">On considère dans cet exercice une matrice réelle $A$ de taille $m\\times n$, $m>n$, un vecteur $b\\in\\mathbb{R}^m$, et on cherche à \"résoudre\" le système\n",
    ">\n",
    ">$$ Ax=b,\\quad{} x\\in\\mathbb{R}^n. $$\n",
    ">\n",
    ">En pratique, un tel système n'a souvent pas de solution, et on cherche donc plutôt un $x$ qui minimise l'erreur :\n",
    ">\n",
    ">$$ \\left\\Vert Ax-b \\right\\Vert_2 = \\min_{y\\in\\mathbb{R}^n} \\left\\Vert Ay-b \\right\\Vert_2. \\qquad{} (1)$$\n",
    ">\n",
    ">On va pour cela utiliser une décomposition $QR$ de $A$, c'est à dire deux matrices $Q$ et $R$, respectivement orthogonale de taille $m\\times m$ et triangulaire de taille $m\\times n$, telles que $A=QR$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "On rappelle que si $Q$ est une matrice orthogonale, $Q^T Q=I$ et $\\left\\Vert Qy \\right\\Vert_2 = \\left\\Vert y \\right\\Vert_2$ pour tout vecteur $y$. En déduire une manière de trouver un vecteur $x$ satisfaisant (1) à l'aide de la factorisation $QR$ et la résolution d'un système triangulaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 \n",
    "\n",
    "**<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Utiliser cette méthode pour résoudre le système surdimensionné $Bx=b$, avec \n",
    "\n",
    "$$\n",
    "    B=\\begin{pmatrix}\n",
    "      10 & 1 & 4  \\\\\n",
    "      1  & 3 & 5 \\\\\n",
    "      4 & 5  & 10 \\\\\n",
    "      2 & 5  & 6 \\\\\n",
    "      1 & 8  & 6 \\\\\n",
    "      5 & 9  & -4 \\\\\n",
    "      0 & -1 & 7 \n",
    "    \\end{pmatrix}\\quad{} \n",
    "    \\text{ et }\\quad{}\n",
    "    b = \\begin{pmatrix}\n",
    "    14\\\\15\\\\26\\\\28\\\\47\\\\70 \\\\-15\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "et vérifier la valeur de la norme $\\|A y - b\\|$ pour $y = x + e_i$ où $e_i = (1,0,0)^T$, $(0,1,0)^T$ et $(0,0,1)^T$.    \n",
    "\n",
    "*Indication :* Utiliser la fonction *numpy.linalg.qr.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[10,1,4],[1,3,5],[4,5,10],[2,5,6],[1,8,6],[5,9,-4],[0,-1,7]])\n",
    "b = np.array([14,15,26,28,47,70,-15])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Solution : \", )\n",
    "print(\"B x =\", , \"norme Bx-b\", )\n",
    "\n",
    "print(\"B y =\", , \"norme By-b\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Stockage de matrice et Laplacien\n",
    "\n",
    ">L'objectif de cet exercice est d'adapter, dans le cas des matrices creuses (c'est à dire qui contiennent une majorité de zéros), les algorithmes de résolution de systèmes linéaires. On applique ici ces différentes méthodes pour la résolution des problèmes suivants\n",
    ">\n",
    ">$$\\begin{aligned} \\text{1D : }& \\left\\{ \\begin{array}{l} -\\Delta u(x)   = x^3        \\quad{} \\text{ si } x  \\in[0,1] \\\\ u(0  ) = 0 = u(1  ), \\end{array}\\right. \\qquad{} &(2)\\\\\n",
    "   \\text{2D : }& \\left\\{ \\begin{array}{l} -\\Delta u(x,y) = 5\\pi^2 \\sin(\\pi x)\\sin(2\\pi y)  \\quad{} \\text{ si } x,y\\in[0,1] \\\\ u(0,y) = 0 = u(1,y) = u(x,0) = u(x,1). \\end{array}\\right.\\qquad{} &(3) \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<big> Cas 1D :</big>**\n",
    "\n",
    ">On considère une matrice $C$ tridiagonale, i.e. dont les seuls coefficients $C_{i,j}$ éventuellement non-nuls sont ceux tels que $|i-j| \\le 1$.\n",
    ">On écrit cette matrice $C$ sous la forme\n",
    ">\n",
    ">$$ C = \\left( \\begin{array}{cccccc}\n",
    "    a_1    & b_2    & 0       &\\dots   & 0 \\\\\n",
    "    c_1    & a_2    & b_3     & \\ddots& \\vdots  \\\\\n",
    "    0      & \\ddots & \\ddots &\\ddots  &0\\\\\n",
    "    \\vdots & \\ddots & \\ddots &\\ddots  & b_{N}\\\\\n",
    "    0      & \\dots  &  0   &   c_{N-1}  & a_N\n",
    "  \\end{array}\\right). $$\n",
    "> \n",
    ">Pour les applications numériques, on fixera \n",
    ">\n",
    ">$$ a_i = \\frac{2}{h^2}, \\quad{} b_i = -\\frac{1}{h^2} \\quad{} \\text{et} \\quad{} c_i = -\\frac{1}{h^2} \\quad{} \\text{avec} \\quad{} h = \\frac{1}{N+1}, \\quad{} N = 2048. \\qquad{}(4)$$\n",
    ">\n",
    ">Ici $h$ est un pas d'espace. Cette matrice correspond à une discrétisation de l'opérateur $-\\Delta$, dont la construction est donnée dans le cours et sera reprise plus tard en PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : Matrices pleines \n",
    "\n",
    "$1$. **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Implémenter une fonction qui renvoie la matrice $C$ de la discrétisation de $-\\Delta$ décrite en (4), pour un $N$ donné. Afficher le résultat obtenu pour $N=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moins_Laplacien_1D_plein(N):\n",
    "    \"\"\"\n",
    "    crée la matrice NxN correspondant à la discrétisation de -\\Delta en 1D\n",
    "    ----------   \n",
    "    parametre:\n",
    "    N   : taille de la matrice\n",
    "    \n",
    "    valeur de retour:\n",
    "    matrice de taille NxN\n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester votre fonction avec N = 3 \n",
    "\n",
    "print(\"Matrice du Laplacien :\\n\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** On utilisera ici les valeurs numériques données dans (4) :\n",
    "- Utiliser la fonction *lu_factor* de *scipy.linalg* pour construire deux matrices $L$ et $U$ respectivement triangulaire inférieure et supérieure telles que $C=LU$. \n",
    "- Afficher la valeur $\\max_{i,j}\\left|(C - L U)\\right|_{i,j}$ pour vérifier que les deux matrices sont bien identiques. \n",
    "\n",
    "*Indication :* On vérifiera dans la documentation ce que renvoie cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N       = 2048\n",
    "\n",
    "\n",
    "print(\"Valeur max :\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Résoudre $Cu=f$ avec $f_i = x_i^3$ où $x_i = ih$ pour $i=1,\\dots,N$ en utilisant la factorisation LU précédente et la fonction *lu\\_solve*.\n",
    "    Calculer la solution analytique $x\\mapsto u(x)$ du problème (2) et tracer les courbes $u(x_i)$ et $u_i$ en fonction de $x_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_membre_1D(N):\n",
    "    \"\"\"\n",
    "    crée le second membre de taille N en 1D, donne par f_i = f(x_i)\n",
    "    ----------   \n",
    "    parametre:\n",
    "    N   : taille du vecteur\n",
    "    \n",
    "    valeur de retour:\n",
    "    veteur de taille N\n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2048\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"second membre f(x)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,sol)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"solution u(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Stockage tridiagonal \n",
    "    \n",
    "1) Supposons $L$ et $U$ tridiagonales et respectivement triangulaire inférieure et supérieure de la forme\n",
    "  \n",
    "$$ L = \\left( \\begin{array}{cccccc}\n",
    "    1       & 0     & \\dots  & \\dots    & 0 \\\\\n",
    "    \\gamma_1& 1     & \\ddots &          & \\vdots  \\\\\n",
    "    0       & \\ddots& \\ddots &\\ddots    & \\vdots \\\\\n",
    "    \\vdots  & \\ddots& \\ddots &\\ddots    & 0\\\\\n",
    "    0       & \\dots &  0     & \\gamma_{N-1} & 1\n",
    "  \\end{array}\\right), \\qquad{}\n",
    "  U = \\left( \\begin{array}{cccccc}\n",
    "    \\alpha_1&\\beta_2 &       0 & \\dots  & 0 \\\\\n",
    "    0       &\\alpha_2& \\beta_3 &\\ddots & \\vdots  \\\\\n",
    "    \\vdots  & \\ddots& \\ddots &\\ddots    & 0\\\\\n",
    "    \\vdots &       & \\ddots &\\ddots    & \\beta_{N}\\\\\n",
    "    0       & \\dots & \\dots  & 0 & \\alpha_N\n",
    "  \\end{array}\\right).$$\n",
    "  \n",
    "   Calculer les coefficients de la matrice produit $LU$ et en déduire la décomposition $LU$ d'une matrice tridiagonale $C$. \n",
    "  \n",
    "2) Combien d'opérations sont nécessaires pour calculer les coefficients de cette décomposition? Combien de coefficients sont stockés? \n",
    "\n",
    "3) De quel coefficients des matrices $C$, $L$ et $U$ a-t'on besoin pour calculer les $i$-emes coefficients $\\alpha_i$, $\\beta_i$ et $\\gamma_i$ des matrices $L$ et $U$? Proposer un ordre dans lequel faire les calculs pour que chaque coefficient $\\alpha_i$, $\\beta_i$ et $\\gamma_i$ ne dépendent que de coefficients connus, c'est-à-dire uniquement de la matrice $C$ et de coefficients de $L$ et $U$ déjà calculés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Implémenter une fonction qui renvoie la discrétisation de $-\\Delta$ décrite en (4) en utilisant un stockage sous forme tridiagonale ou bande\n",
    " pour un $N$ donné, c'est à dire de la forme\n",
    " \n",
    "$$\\tilde{C} = \\left( \\begin{array}{c|c|c|c|c} 0 & b_{2} & \\dots & b_{N-1} & b_{N}\\\\ \\hline  a_{1} & a_{2} & \\dots & a_{N-1} & a_{N} \\\\ \\hline c_{1} & c_{2} & \\dots & c_{N-1} & 0 \\end{array} \\right) = \\left( \\begin{array}{l} b \\\\ a \\\\ c \\end{array}\\right) \\in \\mathbb{R}^{3,N},$$\n",
    " \n",
    "tel qu'on ne stocke que les composantes non-triviales de $C$.  Afficher le résultat obtenu pour $N=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moins_Laplacien_1D_tridiag(N):\n",
    "    \"\"\"\n",
    "    crée la matrice 3xN correspondant à la discrétisation de -\\Delta en 1D, en format tridiagonal\n",
    "    ----------   \n",
    "    parametre:\n",
    "    N   : taille de la matrice\n",
    "    \n",
    "    valeur de retour:\n",
    "    matrice de taille 3xN\n",
    "    \"\"\"\n",
    "   \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test avec N=3\n",
    "\n",
    "print(\"Laplacien au format bande :\\n\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) **<font color=black><span style=\"background-color:skyblue\"> À rendre :</span></font>** Résoudre le système $Cu = f$ avec les valeurs numériques (4) en utilisant la fonction *solve_banded* (https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve_banded.html) de *scipy.linalg* qui résoud un système au format bande. \n",
    "\n",
    "Comparer la précision des résultats et les temps d'execution (en utilisant *%timeit*, un exemple vous est donné dans la cellule suivante) avec ceux obtenus avec la matrice pleine à la question 1. Commenter les avantages de ce stockage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2**6\n",
    "A = np.array([[i**j for j in range(N)] for i in range(N)],dtype=float) + N * np.eye(N)\n",
    "b = np.ones(N)\n",
    "\n",
    "%timeit lin.solve(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2048\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,sol)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"solution u(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) **<font color=black><span style=\"background-color:deepskyblue\"> Bonus :</span></font>** On va maintenant implémenter l'algorithme de décomposition LU basé sur un stockage tridiagonal de la matrice, c'est-à-dire qu'on ne stocke que les composantes non-triviales des matrices $C$, $L$ et $U$. On écrira pour cela\n",
    "\n",
    "$$\\tilde{L} = \\left( \\gamma_{1}, \\gamma_{2}, \\dots, \\gamma_{N-1}, 0 \\right) \\in\\mathbb{R}^{1,N}, \\qquad{}\n",
    "      \\tilde{U} = \\left( \\begin{array}{c|c|c|c|c} 0 & \\beta_2 &  \\dots & \\beta_{N-1}& \\beta_{N} \\\\ \\hline \\alpha_{1} & \\alpha_{2} & \\dots & \\alpha_{N-1} & \\alpha_{N} \\end{array} \\right) \\in\\mathbb{R}^{2,N}. \\qquad{} (5)$$\n",
    "      \n",
    "Tester votre algorithme sur la matrice \n",
    "  \n",
    "$$C = \\left(\\begin{array}{ccc} 2 & 1 & 0 \\\\ -1 & 3 & 1 \\\\ 0 & 1 & 4 \\end{array}\\right). \\qquad{}(6) $$\n",
    "\n",
    "*Afin de valider le résultat, on pourra rentransformer les matrices $\\tilde{L}$ et $\\tilde{U}$ obtenues en matrices pleines, et vérifier que leur produit redonne bien C.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tridiag_factorize_lu(C):\n",
    "    \"\"\"\"\n",
    "    calcule la factorisation LU d'une matrice stockée en format tridiagonal\n",
    "    ----------   \n",
    "    parametres:\n",
    "    C   : matrice de taille 3xN, correspondant au stockage tridiagonal d'une matrice NxN\n",
    "    \n",
    "    valeur de retour:\n",
    "    les matrices L et U, de taille 1xN et 2xN respectivement\n",
    "    \"\"\"\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C    = \n",
    "\n",
    "\n",
    "print(\"L calculé :\\n \", )\n",
    "print(\"U calculé :\\n \", ,\"\\n\")\n",
    "print(\"comparaison : LU scipy :\\n \",  ,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) **<font color=black><span style=\"background-color:deepskyblue\"> Bonus :</span></font>** Adapter et implémenter les algorithmes de remontée et de descente adaptés aux matrices triangulaires stockées sous forme (5). Tester votre algorithme pour la résolution de $C u = f$ avec $C$ donnée en (6) et $f = (1,\\ 1,\\ 1)^T$, en utilisant la décomposition $LU$ de $C$ obtenue à la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descente(L, b):\n",
    "    \"\"\"\n",
    "    résout le système linéaire Ly=b, L provenant de la factorisation LU d'une matrice au format tridiagonal\n",
    "    ----------   \n",
    "    parametre:\n",
    "    L   : matrice de taille 1xN\n",
    "    b   : vecteur de taille N\n",
    "    \n",
    "    valeur de retour:\n",
    "    y   : vecteur de taille N\n",
    "    \"\"\" \n",
    "    return \n",
    "\n",
    "\n",
    "def remontee(U, y):\n",
    "    \"\"\"\n",
    "    résout le système linéaire Ux=y, U provenant de la factorisation LU d'une matrice au format tridiagonal\n",
    "    ----------   \n",
    "    parametre:\n",
    "    U   : matrice de taille 2xN\n",
    "    y   : vecteur de taille N\n",
    "    \n",
    "    valeur de retour:\n",
    "    x   : vecteur de taille N\n",
    "    \"\"\"\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b    = np.ones(3)\n",
    "C    = \n",
    "\n",
    "\n",
    "\n",
    "print(\"solution de L y = b\", )\n",
    "print(\"produit L y : \", )\n",
    "print(\"RHS\", b,\"\\n\")\n",
    "\n",
    "\n",
    "print(\"solution U x = y: \", )\n",
    "print(\"produit U x : \", )\n",
    "print(\"RHS\", ,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<big>Cas 2D :</big>**\n",
    "\n",
    ">On considère maintenant une matrice bande, i.e. dont les seuls coefficients $C_{i,j}$ éventuellement non-nuls sont ceux tels que $|i-j| \\le K$, où $K>0$ est appelée la largeur de bande.\n",
    ">\n",
    ">On utilisera pour les applications numériques la matrice $C \\in \\mathbb{R}^{N^2\\times N^2}$ définie par\n",
    ">\n",
    ">$$\n",
    "    C = \\left( \\begin{array}{c|c|c|c|c}\n",
    "      D    & -I/h^2    &0 &\\dots   & 0 \\\\ \\hline\n",
    "      -I/h^2    & D    & \\ddots&  \\ddots &\\vdots  \\\\ \\hline\n",
    "      0    &  \\ddots   & \\ddots & \\ddots& 0  \\\\ \\hline\n",
    "      \\vdots   & \\ddots &\\ddots & \\ddots &-I/h^2\\\\ \\hline\n",
    "      0      & \\dots & 0 &   -I/h^2  & D\n",
    "    \\end{array}\\right), \\quad{}\n",
    "    D = \\left( \\begin{array}{ccccc}\n",
    "      4/h^2    & -1/h^2  & 0  & \\dots   & 0 \\\\\n",
    "      -1/h^2    & 4/h^2    & \\ddots& \\ddots& \\vdots  \\\\   \n",
    "      0      & \\ddots & \\ddots & \\ddots  & 0\\\\\n",
    "      \\vdots & \\ddots & \\ddots  & \\ddots & -1/h^2\\\\\n",
    "      0      & \\dots  & 0 & -1/h^2  & 4/h^2\n",
    "    \\end{array}\\right) \\in\\mathbb{R}^{N\\times N},\n",
    "    \\qquad{} (7)\n",
    "$$\n",
    ">\n",
    ">où $I$ est la matrice identité de taille $N$ et $h = \\frac{1}{N+1}$. Cette matrice correspond à une discrétisation de l'opérateur $-\\Delta$ en 2D. Pour les applications, on prendra $N=64$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 : Matrices pleines \n",
    "\n",
    "$1$. **<font color=black><span style=\"background-color:deepskyblue\"> Bonus :</span></font>** Implémenter une fonction qui renvoie la discrétisation de $-\\Delta$ en dimension 2 décrite en (7), pour un $N$ donné. Afficher le résultat obtenu pour $N=3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moins_Laplacien_2D_plein(N):\n",
    "    \"\"\"\n",
    "    crée la matrice N^2xN^2 correspondant à la discrétisation de -\\Delta en 2D\n",
    "    ----------   \n",
    "    parametre:\n",
    "    N   : taille de la matrice\n",
    "    \n",
    "    valeur de retour:\n",
    "    matrice de taille N^2xN^2\n",
    "    \"\"\"\n",
    "  \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "\n",
    "\n",
    "print(\"Laplacien 2D :\\n\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. **<font color=black><span style=\"background-color:deepskyblue\"> Bonus :</span></font>** \n",
    "- En utilisant la fonction *solve* de *numpy.linalg*, résoudre le système $Cu = f$ avec $f_{(i-1)N+j} = f(x_i,y_j) = 5\\pi^2 \\sin(\\pi x_i)\\sin(2\\pi y_j)$ où $x_i = ih$ et $y_j = jh$ pour $i,j=1,\\dots,N$. \n",
    "- Vérifier que $u(x,y) = \\sin(\\pi x)\\sin(2\\pi y)$ est solution du problème (3).\n",
    "- Tracer les fonctions $u$ théorique et numérique avec la fonction *contourf*.\n",
    "- Calculer l'erreur avec le vecteur obtenu. \n",
    "- Commenter la taille de la matrice $A$ stockée (**sauvegarder avant d'executer**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_membre_2D(N):\n",
    "    \"\"\"\n",
    "    crée le second membre de taille N^2 en 2D, donne par f_i = f(x_i)\n",
    "    les coposantes sont stockées sous la forme \n",
    "    f(x_0,y_0), ..., f(x_{N-1},y_0), f(x_0, y_1), ..., f(x_{N-1},y_1)...\n",
    "    ----------   \n",
    "    parametre:\n",
    "    N   : taille du vecteur \n",
    "    \n",
    "    valeur de retour:\n",
    "    veteur de taille N^2\n",
    "    \"\"\"\n",
    "   \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "\n",
    "\n",
    "print(\"2nd membre :\\n\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N          = 64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nx     = N\n",
    "ny     = N\n",
    "dx     = 1./(nx+1)\n",
    "dy     = 1./(ny+1)\n",
    "x      = np.linspace(1,nx,nx)*dx\n",
    "y      = np.linspace(1,ny,ny)*dy\n",
    "xx, yy = np.meshgrid(x, y, indexing='xy')\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(xx,yy, )\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(xx,yy, )\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : Matrices bandes\n",
    "\n",
    "On stocke désormais la matrice sous forme bande, c'est-à-dire qu'on écrit \n",
    "\n",
    "$$\\tilde{C} = \\left(\n",
    "      \\begin{array}{c|c|c|c|c|c}\n",
    "        0             & \\dots & 0        & C_{1,K+1} & \\dots   & C_{N-K,N}\\\\\n",
    "        \\hline \\vdots & \\ddots & \\ddots & C_{2,K+1} &\\dots   & C_{N-K+1,N}\\\\\n",
    "        \\hline 0      & C_{1,2} &          &          &         & \\vdots    \\\\\n",
    "        \\hline C_{1,1} & C_{2,2} & \\dots  & \\dots     & \\dots   & C_{N,N} \\\\\n",
    "        \\hline C_{2,1} & C_{3,2} & \\dots   & \\dots    & C_{N,N-1} & 0 \\\\\n",
    "        \\hline \\vdots &        &         &          &         & \\vdots \\\\\n",
    "        \\hline C_{K+1,1} & \\dots & C_{N,N-K} & 0       & \\dots   &  0\n",
    "      \\end{array} \\right) \\in \\mathbb{R}^{2K+1,N}.$$\n",
    "      \n",
    "Utiliser la fonction *solve\\_banded* de *scipy* exploitant cette structure bande pour résoudre le problème $Au = f$. Comparer la vitesse d'execution (avec %timeit) et la taille de la matrice utilisée avec la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moins_Laplacien_2D_bande(N):\n",
    "    \"\"\"\n",
    "    crée la matrice correspondant à la discrétisation de -\\Delta en 2D sous format bande\n",
    "    ----------   \n",
    "    parametre:\n",
    "    N   : taille de la matrice\n",
    "    \n",
    "    valeur de retour:\n",
    "    matrice de taille N^2xN^2 sous format bande\n",
    "    \"\"\" \n",
    "  \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N               = 64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nx     = N\n",
    "ny     = N\n",
    "dx     = 1./(nx+1)\n",
    "dy     = 1./(ny+1)\n",
    "x      = np.linspace(1,nx,nx)*dx\n",
    "y      = np.linspace(1,ny,ny)*dy\n",
    "xx, yy = np.meshgrid(x, y, indexing='xy')\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(xx,yy, )\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.contourf(xx,yy, )\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
